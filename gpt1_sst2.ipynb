{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1EQuTxjfpHm"
      },
      "source": [
        "# GPT1 - SST2 Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XDG9RShsoDe2",
        "outputId": "5cf8181e-a365-44fe-c5f9-8e62eb0fe619"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1u-i07COjz9T",
        "outputId": "63505aac-6a3f-4102-f00b-d259bb6029ee"
      },
      "outputs": [],
      "source": [
        "!pip install spacy ftfy==4.4.3\n",
        "!python -m spacy download en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dK4mSE7HYTh8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    OpenAIGPTTokenizer,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "\n",
        "from transformers import (\n",
        "    pipeline,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    OpenAIGPTModel,\n",
        "    OpenAIGPTForSequenceClassification,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "34d6ab8e017a46b7b310dd0d48e94131",
            "0d86f0582c9a4c718f1c5f481fb6723d",
            "8ee7272bcab640739238d833f8d75efe",
            "c6379858ea1a41159589b3d054315a49",
            "869ab167b714421490b26af2e98aa8f2",
            "1093a5e03f984194b059fb25cebefe11",
            "8d7b8a33554942148ac2ae87e85603dc",
            "6238ca5405284f93ac42c9aedc259776",
            "bc994b5e4cec4675b0ad561c1bd5e623",
            "f65206ab1ac04c22a503a1c1fff345ee",
            "bfed895051a847b4a8e67a4af4a74903",
            "f3d116ddfed942a08e93a8ee1f60c8ce",
            "349b49db2a7249639146a088d3c143c0",
            "c46b45bf64824551a4ce996e3b36daef",
            "f33ac2f33f97408a8fed6c1103abf2a3",
            "c8c93c52c31743c4a34649c6927d46ad",
            "f7505e4c06b54346906a63f8eb5d2733",
            "6ccbc36d9fe74cf296b165d63bc7ab96",
            "24fcbcd4f93c46548a7942efd0b23ca7",
            "40005734eb7e46b7b8516a31ec33d6a5"
          ]
        },
        "id": "kPgRCa3rYVBS",
        "outputId": "77b691f5-ff6d-4efd-8d4c-b42c04d6fa91"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZfMYi36Zi5I"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0RvnlkMaC8a"
      },
      "source": [
        "## Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QpzZpTspZkiB",
        "outputId": "7aca8faf-2876-41e7-8127-f9c5b707ac63"
      },
      "outputs": [],
      "source": [
        "#sst2 = load_dataset(\"stanfordnlp/sst2\")\n",
        "sst2 = load_dataset(\"nyu-mll/glue\", \"sst2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyfTGVZoaGXb"
      },
      "source": [
        "## Analyzing\n",
        "\n",
        "Stanford Sentiment Treebank (SST) is a 5-class sentiment analysis dataset of movie reviews taken from Rotten Tomatoes. It was published as a part [\"Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\"](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf) paper in 2013.\n",
        "\n",
        "Then, its binary version (SST-2) was standardized by the [GLUE benchmark](https://openreview.net/pdf?id=rJ4km2R5t7) where train and test splits are specifically provided. In HuggingFace Glue Benchmark, we have a small sized validation split too. Each data sample is actually the composition of ***sentence*** and ***label*** in a dictionary.\n",
        "\n",
        "- Positive Review: label 1\n",
        "- Negative Review: label 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wa1CgtUaP_T",
        "outputId": "c7321c26-07bd-4565-8238-54d1f144abea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size:  67349\n",
            "Valid size:  872\n",
            "Test size:  1821\n",
            "\n",
            "Type of a sample:  <class 'dict'>\n",
            "Sentence:  hide new secretions from the parental units \n",
            "Label:  0\n"
          ]
        }
      ],
      "source": [
        "# train, valid and test dataset size\n",
        "print(\"Train size: \", len(sst2[\"train\"]))\n",
        "print(\"Valid size: \", len(sst2[\"validation\"]))\n",
        "print(\"Test size: \", len(sst2[\"test\"]))\n",
        "print()\n",
        "\n",
        "train_set = sst2[\"train\"]\n",
        "valid_set = sst2[\"validation\"]\n",
        "test_set = sst2[\"test\"]\n",
        "\n",
        "# a data sample = <text, label> dict\n",
        "print(\"Type of a sample: \", type(train_set[0]))\n",
        "print(\"Sentence: \", train_set[0][\"sentence\"][:100])\n",
        "print(\"Label: \", train_set[0][\"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3QTBGLVcwyK"
      },
      "source": [
        "## Text Preprocessing - Tokenizer\n",
        "\n",
        "### 1. Structure of Tokenizer:\n",
        "\n",
        "GPT-1 tokenizer utilizes byte-pair encoding [\\[1\\]](https://huggingface.co/learn/nlp-course/en/chapter6/5#implementing-bpe), with a vocabulary of 40478 tokens. While index 0 is exclusively reserved for unknown tokens, and padding token is discarded. The main reason for this lies behind the followed pre-training strategy:\n",
        "\n",
        "GPT-1 architecture was generative pre-trained on fixed-length blocks of 512 tokens. In other words, the dataset was partitioned into contiguous sequences of exactly 512 tokens. Hence, every sample in a batch has always 512-tokens length; there was no need for padding. However, to be able to finetune it with variable-length sequences in SST2 dataset, we define a padding token and inserted it into the tokenizer.\n",
        "\n",
        "### 2. Truncation and Padding:\n",
        "\n",
        "To be able to finetune GPT-1 architecture with batched inputs, we need to pad shorter sequences, and truncate the sequences longer than 512 tokens in the batch. One of the controversial issues is in which direction we need to apply truncation and padding operations.\n",
        "\n",
        "***A. Left and Right Padding:***\n",
        "\n",
        "You can encounter in some resources that left padding is recommended for sentence-level prediction tasks like sentiment analysis. Since GPT models process the text autoregressively from left to right, each token representation depends on all preceding tokens, meaning that final token effectively aggregates information from the entire sequence. Because of this, classification heads at the top of GPT models account for last token [\\[2\\]](https://huggingface.co/docs/transformers/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification). In that case, leaving pad tokens at the left side and preserving actual text content to the right helps model to attends to the rightmost content as actual text context. This ensures that last token encapsulates the interpretation of whole text and model predictions are not contaminated by padding tokens.\n",
        "\n",
        "Besides, GPT models are decoder-only architectures, so while generating an asnwer, they actually iterate over your prompt. GPT-based arcihtectures are not trained to generate text from pad tokens, which interrupts the generation of continuous semantic information. Hence, left-sided padding can be useful [\\[3\\]](https://huggingface.co/docs/transformers/llm_tutorial#wrong-padding-side).\n",
        "\n",
        "\n",
        "Nevertheless, GPT adapts absolute position embeddings. If you do left padding, you actually push real tokens to higher position indices than they would normally occupy, which can cause a mismatch between how the model was pre-trained and how you are fine-tuning. *\\\"So it is usually advised to pad the inputs on the right rather than the left\\\"* [\\[2\\]](https://huggingface.co/docs/transformers/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification).\n",
        "\n",
        "\n",
        "***B. Left and Right Truncation:***\n",
        "\n",
        "In left-truncation, the final tokens are retained to preserve the portion of text where the meaning often accumulates. This method can be particularly advantageous in sentiment analysis, as evaluative cues frequently appear near the end of a passage. Conversely, right truncation keeps the opening tokens, which may be more beneficial when a task relies on the prompt’s initial content, such as the instructions or sample code, since subsequent queries or responses depend on that foundational context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWrs3zpMc48c",
        "outputId": "a9a66255-5286-41ec-a986-531063729867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size before pad token:  40478\n",
            "Vocabulary size after pad token:  40479\n",
            "Pad token id:  40478\n",
            "Index 0 token:  <unk>\n",
            "Index 40478 token:  <pad>\n"
          ]
        }
      ],
      "source": [
        "# definition of tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"openai-community/openai-gpt\",\n",
        "    truncation_side=\"right\",\n",
        "    padding_side=\"right\")\n",
        "\n",
        "# getting vocabulary and printing vocab-size\n",
        "vocab = tokenizer.get_vocab()\n",
        "print(\"Vocabulary size before pad token: \", len(vocab))\n",
        "\n",
        "\n",
        "# adding pad token\n",
        "# updating vocabulary\n",
        "# printing vocab-size and pad index\n",
        "tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
        "vocab = tokenizer.get_vocab()\n",
        "print(\"Vocabulary size after pad token: \", len(vocab))\n",
        "print(\"Pad token id: \", tokenizer.pad_token_id)\n",
        "\n",
        "# defining inverse vocabulary\n",
        "# printing first and last tokens\n",
        "inv_vocab = {str(value): key for key, value in vocab.items()}\n",
        "print(\"Index 0 token: \", inv_vocab[\"0\"])\n",
        "print(\"Index 40478 token: \", inv_vocab[\"40478\"])\n",
        "\n",
        "# tokenizing the dataset\n",
        "def tokenize(examples):\n",
        "    return tokenizer(examples[\"sentence\"], max_length=512, padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_sst2 = sst2.map(tokenize, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCFiqds7-2dQ"
      },
      "source": [
        "### 2. Batching Tokens\n",
        "\n",
        "* In general, the sentences or paragraphs to be processed by the language model have different length; so after tokenization each sentence has different number of tokens. This is a problem, because batched inputs need to be fixed-size tensors, where padding enters the picture. It adds a special padding token to guarantee that all sequences have same length as the longest one or maximum length accepted by the model [\\[4\\]](https://huggingface.co/docs/transformers/en/pad_truncation#).\n",
        "\n",
        "* Our main purpose is to create a batch of padded samples. To achieve that, [`DataCollatorWithPadding`](https://huggingface.co/docs/transformers/v4.47.1/en/main_classes/data_collator#transformers.DataCollatorWithPadding) can be used. It dynamically pads the sequences to longest length in the batch during collation. As an alternative, all samples in the dataset can be also padded to maximum length, but we do not need this. What we need is that only the samples in the same batch should have same length. At this point, dynamic padding inside the batch becomes more efficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8Qt22j1aAeTu"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp-yarvriRdw"
      },
      "source": [
        "# Evaluate\n",
        "\n",
        "To be able to evaluate the performance of the model during training and validation steps, we need some metrics. The most used ones for classification is accuracy, precision and recall. We can use HF [evaluate](https://huggingface.co/docs/evaluate/en/index) library.\n",
        "\n",
        "We implement `compute_metrics()` function, which will be automatically invoked to calculate 3 evaluation metrics for validation set during training. When multiple metrics are calculated in this function, its return statement needs to be a dictionary [\\[5, ](https://huggingface.co/docs/transformers/en/main_classes/trainer)[6\\]](https://discuss.huggingface.co/t/combine-multiple-metrics-in-compute-metrics-for-validation/90088)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y_uBZ4m1fu77"
      },
      "outputs": [],
      "source": [
        "recall = evaluate.load(\"recall\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "\n",
        "def compute_metrics(preds_labels) -> dict:\n",
        "    preds, labels = preds_labels\n",
        "    preds = np.argmax(preds, axis=1)  # expected shape: (B, 2)\n",
        "\n",
        "    acc = accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
        "    rec = recall.compute(predictions=preds, references=labels)[\"recall\"]\n",
        "    pre = precision.compute(predictions=preds, references=labels)[\"precision\"]\n",
        "\n",
        "    return {\"accuracy\": acc, \"recall\": rec, \"precision\": pre}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ0PhDfrkMlA"
      },
      "source": [
        "# Training\n",
        "\n",
        "GPT-1 classifier is extended version of autoregressive GPT-1 architecture [\\[7\\]](https://huggingface.co/openai-community/openai-gpt#model-details); it has an additional classification layer (only weights, no bias) built on last token. That is why, the architecture needs to the position of the last token. At this point, specification of pad_token_id is important, it allows the model to recognize which one is padding token and easily finds the last token [\\[2\\]](https://huggingface.co/docs/transformers/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pa5zJkp8kOIf",
        "outputId": "3c2cc94b-461b-477c-a1ce-ddb0b766ed81"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of OpenAIGPTForSequenceClassification were not initialized from the model checkpoint at openai-gpt and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Number of parameters:  116537088\n"
          ]
        }
      ],
      "source": [
        "# Dictionaries to map from class ids to corresponding labels or vice versa.\n",
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
        "\n",
        "# instantiating gpt1 classifier\n",
        "model = OpenAIGPTForSequenceClassification.from_pretrained(\"openai-gpt\", num_labels=2)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.config.pad_token_id = 40478\n",
        "\n",
        "print(\"\\nNumber of parameters: \", model.num_parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOrtd7KnyJAC"
      },
      "source": [
        "## Training Arguments and Trainer\n",
        "\n",
        "To train the model, we need to determine hyperparameters, which is handled by `TrainingArguments` [\\[8\\]](https://huggingface.co/docs/transformers/en/main_classes/trainer).\n",
        "\n",
        "- ***output_dir:*** The directory where model predictions and checkpoints will be saved.\n",
        "\n",
        "- ***per_device_train_batch_size:*** When you train your model with multiple GPUs or TPUs, it controls the batch size for each GPU/TPU.\n",
        "\n",
        "- ***per_device_eval_batch_size:*** When you evaluate your model with multiple GPUs or TPUs, it controls the batch size for each GPU/TPU.\n",
        "\n",
        "- ***num_train_epochs:*** How many number of epochs the model will be trained.\n",
        "\n",
        "- ***eval_strategy:*** It can be \"no\", \"steps\", or \"epoch\".\n",
        "    - no: No evaluation is done during training\n",
        "    - steps: Evaluation is done and logged every *\\\"eval_steps\\\"*\n",
        "    - epoch: Evaluation is done at the end of each epoch.\n",
        "\n",
        "\n",
        "- ***save_strategy:*** It can be \"no\", \"steps\", \"epoch\", \"best\".\n",
        "    - no: No ckpt save is done during training\n",
        "    - steps: Ckpt save is done every *\\\"eval_steps\\\"*\n",
        "    - epoch: Ckpt save is done at the end of each epoch.\n",
        "    - best: Ckpt save is done when a new *\\\"best_metric\\\"* achieved.\n",
        "\n",
        "- ***load_best_model_at_end:*** It is a boolean value to make sure whether the best model according to `metric_for_best_model` will be saved or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "rppmG_G_lj0q",
        "outputId": "a5c32ed1-9208-454f-e134-719a75dc37ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9449' max='16840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 9449/16840 1:04:40 < 50:35, 2.43 it/s, Epoch 2.24/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.295824</td>\n",
              "      <td>0.903670</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.941176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.145500</td>\n",
              "      <td>0.317180</td>\n",
              "      <td>0.918578</td>\n",
              "      <td>0.950450</td>\n",
              "      <td>0.895966</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16840' max='16840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16840/16840 1:55:27, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.295824</td>\n",
              "      <td>0.903670</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.941176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.145500</td>\n",
              "      <td>0.317180</td>\n",
              "      <td>0.918578</td>\n",
              "      <td>0.950450</td>\n",
              "      <td>0.895966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.089200</td>\n",
              "      <td>0.363674</td>\n",
              "      <td>0.927752</td>\n",
              "      <td>0.925676</td>\n",
              "      <td>0.931973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.058400</td>\n",
              "      <td>0.421563</td>\n",
              "      <td>0.925459</td>\n",
              "      <td>0.936937</td>\n",
              "      <td>0.918322</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=16840, training_loss=0.1379245318596267, metrics={'train_runtime': 6928.678, 'train_samples_per_second': 38.881, 'train_steps_per_second': 2.43, 'total_flos': 7.0391028252672e+16, 'train_loss': 0.1379245318596267, 'epoch': 4.0})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"gpt1_sst2_right\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_sst2[\"train\"],\n",
        "    eval_dataset=tokenized_sst2[\"validation\"],\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "collapsed": true,
        "id": "qsoujn7f5de0",
        "outputId": "6580a148-58d2-4f48-f91c-556cdf7e34e1"
      },
      "outputs": [],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFk4bcV87Phf"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fCiGcfNL7RMH",
        "outputId": "24b0e0c3-ab67-45cf-e1cb-7d08f098b9ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "model = pipeline(\"sentiment-analysis\", model=\"goktug14/gpt1_sst2_right\")\n",
        "\n",
        "\n",
        "preds = {\"samples\": [], \"classes\": []}\n",
        "\n",
        "for i in range(len(sst2[\"test\"])):\n",
        "    sample = sst2[\"test\"][i]\n",
        "    pred = pipe(sample[\"sentence\"], top_k=1)[0]\n",
        "\n",
        "    preds[\"samples\"].append(sample[\"sentence\"])\n",
        "    preds[\"classes\"].append(pred[\"label\"].split(\"_\")[1])\n",
        "\n",
        "df = pd.DataFrame(preds)\n",
        "df.to_csv(\"./preds.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJrg30d_5xcY"
      },
      "source": [
        "<a name=\"ref\"></a>\n",
        "\n",
        "# References\n",
        "\n",
        "1. [Byte Pair Encoding](https://huggingface.co/learn/nlp-course/en/chapter6/5#implementing-bpe)\n",
        "\n",
        "2. [GPT-1 Sequence Classifier](https://huggingface.co/docs/transformers/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification)\n",
        "\n",
        "3. [Padding Side](https://huggingface.co/docs/transformers/llm_tutorial#wrong-padding-side)\n",
        "\n",
        "4. [Padding and Truncation](https://huggingface.co/docs/transformers/en/pad_truncation#)\n",
        "\n",
        "5. [Compute Metrics and Trainer](https://huggingface.co/docs/transformers/en/main_classes/trainer)\n",
        "\n",
        "6. [Computation of Multiple Metrics Discussion](https://discuss.huggingface.co/t/combine-multiple-metrics-in-compute-metrics-for-validation/90088)\n",
        "\n",
        "7. [OpenAI - GPT1](https://huggingface.co/openai-community/openai-gpt#model-details)\n",
        "\n",
        "8. [Trainer](https://huggingface.co/docs/transformers/en/main_classes/trainer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d86f0582c9a4c718f1c5f481fb6723d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6238ca5405284f93ac42c9aedc259776",
            "placeholder": "​",
            "style": "IPY_MODEL_bc994b5e4cec4675b0ad561c1bd5e623",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "1093a5e03f984194b059fb25cebefe11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8c93c52c31743c4a34649c6927d46ad",
            "placeholder": "​",
            "style": "IPY_MODEL_f7505e4c06b54346906a63f8eb5d2733",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "24fcbcd4f93c46548a7942efd0b23ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "349b49db2a7249639146a088d3c143c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34d6ab8e017a46b7b310dd0d48e94131": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_8d7b8a33554942148ac2ae87e85603dc"
          }
        },
        "40005734eb7e46b7b8516a31ec33d6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6238ca5405284f93ac42c9aedc259776": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ccbc36d9fe74cf296b165d63bc7ab96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24fcbcd4f93c46548a7942efd0b23ca7",
            "placeholder": "​",
            "style": "IPY_MODEL_40005734eb7e46b7b8516a31ec33d6a5",
            "value": "Connecting..."
          }
        },
        "869ab167b714421490b26af2e98aa8f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c46b45bf64824551a4ce996e3b36daef",
            "style": "IPY_MODEL_f33ac2f33f97408a8fed6c1103abf2a3",
            "tooltip": ""
          }
        },
        "8d7b8a33554942148ac2ae87e85603dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "8ee7272bcab640739238d833f8d75efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f65206ab1ac04c22a503a1c1fff345ee",
            "placeholder": "​",
            "style": "IPY_MODEL_bfed895051a847b4a8e67a4af4a74903",
            "value": ""
          }
        },
        "bc994b5e4cec4675b0ad561c1bd5e623": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfed895051a847b4a8e67a4af4a74903": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c46b45bf64824551a4ce996e3b36daef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6379858ea1a41159589b3d054315a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_f3d116ddfed942a08e93a8ee1f60c8ce",
            "style": "IPY_MODEL_349b49db2a7249639146a088d3c143c0",
            "value": false
          }
        },
        "c8c93c52c31743c4a34649c6927d46ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f33ac2f33f97408a8fed6c1103abf2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f3d116ddfed942a08e93a8ee1f60c8ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f65206ab1ac04c22a503a1c1fff345ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7505e4c06b54346906a63f8eb5d2733": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
