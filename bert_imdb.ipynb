{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BERT - IMDB Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dK4mSE7HYTh8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    BertTokenizer,\n",
        "    BertTokenizerFast,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "\n",
        "from transformers import (\n",
        "    pipeline,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    AutoModel,\n",
        "    AutoModelForSequenceClassification,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "fdb1b40087064990a056c77a034aab4f",
            "63c519f3c11b4810952d071c840c9550",
            "5a9c9937048d4813b8ba80427ac499b4",
            "447a72e2a7cc4f0e8c7149faf1599671",
            "994cd258b30a4876b2c09bb94e38fec3",
            "940a3e171ca04d80bd7439f87eb65da6",
            "bbd9cffffed443f9a761ed4a6f171791",
            "7e7ea7d05c9c44909cd3c56de00d1992",
            "b8a64962cdeb4eae98a4b7389db1adc9",
            "700f55d9671d4d7a971886881e1b452c",
            "2f5d190020314cb2992230a56054f056",
            "7a7c5d7b811b4a6bb8d2ed03d7e06180",
            "c5996703100c4e97ab2fd28d5963b73d",
            "a5c858de69d34da396e21d69dda47175",
            "5241f8a6069f4c728f7dcf2ff920f297",
            "f9ca49c2047c46b789ff200a4363361a",
            "680770bcd6ac404f8fe6c16026ed894a",
            "8e83297ee54145048cb2dee5ec7c252e",
            "d964f25e76be4ecc8e24a075b8d50282",
            "a265fa8289cd40609cd545ab1b6a37e7"
          ]
        },
        "id": "kPgRCa3rYVBS",
        "outputId": "7be77476-079c-4c53-a554-a3e4ef489e28"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdb1b40087064990a056c77a034aab4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZfMYi36Zi5I"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0RvnlkMaC8a"
      },
      "source": [
        "## Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpzZpTspZkiB",
        "outputId": "b2992297-fbf1-4999-ba58-1888c84f78b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "imdb = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyfTGVZoaGXb"
      },
      "source": [
        "## Analyzing\n",
        "\n",
        "Imdb dataset [\\[2\\]](https://huggingface.co/datasets/stanfordnlp/imdb) is partitioned into train and test splits, each with 25k number of samples. A data sample is actually the composition of ***text*** and ***label*** in a dictionary.\n",
        "\n",
        "- Positive Review: label 1\n",
        "- Negative Review: label 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wa1CgtUaP_T",
        "outputId": "55853e32-f81c-4954-a3bf-c64055c54e2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size:  25000\n",
            "Test size:  25000\n",
            "\n",
            "Type of a sample:  <class 'dict'>\n",
            "Text:  I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n",
            "Label:  0\n"
          ]
        }
      ],
      "source": [
        "# train/test dataset size\n",
        "print(\"Train size: \", len(imdb[\"train\"]))\n",
        "print(\"Test size: \", len(imdb[\"test\"]))\n",
        "print()\n",
        "\n",
        "train_set = imdb[\"train\"]\n",
        "test_set = imdb[\"test\"]\n",
        "\n",
        "# a data sample = <text, label> dict\n",
        "print(\"Type of a sample: \", type(train_set[0]))\n",
        "print(\"Text: \", train_set[0][\"text\"])\n",
        "print(\"Label: \", train_set[0][\"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3QTBGLVcwyK"
      },
      "source": [
        "## Text Preprocessing - Tokenizer\n",
        "\n",
        "### 1. Structure of Tokenizer:\n",
        "\n",
        "In HuggingFace, tokenizers are generally provided in two different forms:\n",
        "\n",
        " - Standard tokenizers → python-based\n",
        " - Fast tokenizers → rust-based\n",
        "\n",
        "Being implemented in Rust provides with tokenizers additional acceleration while doing batched-tokenization. Furthermore, fast tokenizers have more advanced alignment methods to map between original string and token space [\\[3, ](https://huggingface.co/docs/transformers/main_classes/tokenizer)[4\\]](https://discuss.huggingface.co/t/difference-betweeen-distilberttokenizerfast-and-distilberttokenizer/5961/2).\n",
        "\n",
        "Here, an uncased BERT tokenizer [\\[5\\]](https://huggingface.co/google-bert/bert-base-uncased) is loaded to split the given text as input into a series of tokens. The function `imbdb.map()` is suitable for this; it requires a pre-processing function to be applied to each of its samples in batched version [\\[6\\]](https://huggingface.co/docs/datasets/en/about_map_batch). To realize this, we define `tokenize()` function, which sends a call to the instance function `__call__()` of *PreTrainedTokenizerBase* class [\\[7\\]](https://huggingface.co/docs/transformers/internal/tokenization_utils). It tokenizes the text and truncates the sequences if they are longer than maximum length in BERT.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "13d535dfad0d40f9b06fbab79d0e4dd7",
            "2a5d61380ab744e591affa76f4847473",
            "09c0b13193bf41499dbea7c1f70c1ad9",
            "3786b632bca74e3d9a3b9a38a980719b",
            "2ee2e2b7a7724c9cb7d2da514f683777",
            "693c3b0c2ee242f8a7aa40302fc25124",
            "a49e851e0dc34877b59a7fc536c54b9c",
            "8819eaa0882a429ca6e3c1c56997be82",
            "4f7ac23eb3404a7fbd96a57252df8821",
            "91851d9d18514c17acc38ccee0189626",
            "ee434fe3283946329078c09d61bf3eaf"
          ]
        },
        "id": "HWrs3zpMc48c",
        "outputId": "261e6b9a-42f9-4fe0-c233-83f6e2ad0df3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It is BertTokenizer:  False\n",
            "It is BertTokenizerFast:  True\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13d535dfad0d40f9b06fbab79d0e4dd7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
        "\n",
        "print(\"It is BertTokenizer: \", isinstance(tokenizer, BertTokenizer))\n",
        "print(\"It is BertTokenizerFast: \", isinstance(tokenizer, BertTokenizerFast))\n",
        "\n",
        "# Inheritance: BertTokenizerFast -> PreTrainedTokenizerFast -> PreTrainedTokenizerBase\n",
        "# Instance call to tokenizer is made by tokenize() function.\n",
        "# That call invoke __call__ method of PreTrainedTokenizerBase class [7].\n",
        "# In that way, it tokenizes one or several sequence(s) for the model.\n",
        "# It returns \"BatchEncoding\" object [7].\n",
        "\n",
        "def tokenize(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "tokenized_imdb = imdb.map(tokenize, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaM636NC04rW"
      },
      "source": [
        "### 2. Tokens and Vocabulary:\n",
        "\n",
        "The function `map()` generates a new dataset in which each text is represented by a series of tokens. By `batched=True` option, multiple elements of the dataset is processed at once.  \n",
        "\n",
        "These tokens are either sub-words or the most repeated full-words. This approach is called *WordPiece*; some prefixes, suffixes and sub-sections in English are highly repetitive in many different words, so they are chosen as tokens. Their different combinations can derive distinct words; no need to save every word as a token. Each token is represented by an index value, which is encoded by an *Embedding* layer to be fed into the model [\\[8\\, ](https://www.youtube.com/watch?v=zHvTiHr506c)[9\\]](https://huggingface.co/docs/transformers/en/tokenizer_summary).\n",
        "\n",
        "Tokenizers provide relevant vocubulary by `get_vocab()` function. It returns a dict of token-index pairs. You can reverse it so that you can map from indices to textual tokens, or you can count the number of entries to see the size of vocabulary.\n",
        "\n",
        "\\\\\n",
        "\n",
        "**Tokenizers and Models:**\n",
        "\n",
        "* ***Unigram:*** XLNet, ALBERT\n",
        "* ***WordPiece:*** BERT, DistilBERT\n",
        "* ***Byte-Pair Encoding:*** GPT-2, RoBERTa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh81FkAJ1cb3",
        "outputId": "1fee47fb-2383-4777-94b9-2d23bddb0e9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample 1 - Text:  I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n",
            "Sample 1 - Token indices:  [101, 1045, 12524, 1045, 2572, 8025, 1011, 3756, 2013, 2026, 2678, 3573, 2138, 1997, 2035, 1996, 6704, 2008, 5129, 2009, 2043, 2009, 2001, 2034, 2207, 1999, 3476, 1012, 1045, 2036, 2657, 2008, 2012, 2034, 2009, 2001, 8243, 2011, 1057, 1012, 1055, 1012, 8205, 2065, 2009, 2412, 2699, 2000, 4607, 2023, 2406, 1010, 3568, 2108, 1037, 5470, 1997, 3152, 2641, 1000, 6801, 1000, 1045, 2428, 2018, 2000, 2156, 2023, 2005, 2870, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 5436, 2003, 8857, 2105, 1037, 2402, 4467, 3689, 3076, 2315, 14229, 2040, 4122, 2000, 4553, 2673, 2016, 2064, 2055, 2166, 1012, 1999, 3327, 2016, 4122, 2000, 3579, 2014, 3086, 2015, 2000, 2437, 2070, 4066, 1997, 4516, 2006, 2054, 1996, 2779, 25430, 14728, 2245, 2055, 3056, 2576, 3314, 2107, 2004, 1996, 5148, 2162, 1998, 2679, 3314, 1999, 1996, 2142, 2163, 1012, 1999, 2090, 4851, 8801, 1998, 6623, 7939, 4697, 3619, 1997, 8947, 2055, 2037, 10740, 2006, 4331, 1010, 2016, 2038, 3348, 2007, 2014, 3689, 3836, 1010, 19846, 1010, 1998, 2496, 2273, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2054, 8563, 2033, 2055, 1045, 2572, 8025, 1011, 3756, 2003, 2008, 2871, 2086, 3283, 1010, 2023, 2001, 2641, 26932, 1012, 2428, 1010, 1996, 3348, 1998, 16371, 25469, 5019, 2024, 2261, 1998, 2521, 2090, 1010, 2130, 2059, 2009, 1005, 1055, 2025, 2915, 2066, 2070, 10036, 2135, 2081, 22555, 2080, 1012, 2096, 2026, 2406, 3549, 2568, 2424, 2009, 16880, 1010, 1999, 4507, 3348, 1998, 16371, 25469, 2024, 1037, 2350, 18785, 1999, 4467, 5988, 1012, 2130, 13749, 7849, 24544, 1010, 15835, 2037, 3437, 2000, 2204, 2214, 2879, 2198, 4811, 1010, 2018, 3348, 5019, 1999, 2010, 3152, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2079, 4012, 3549, 2094, 1996, 16587, 2005, 1996, 2755, 2008, 2151, 3348, 3491, 1999, 1996, 2143, 2003, 3491, 2005, 6018, 5682, 2738, 2084, 2074, 2000, 5213, 2111, 1998, 2191, 2769, 2000, 2022, 3491, 1999, 26932, 12370, 1999, 2637, 1012, 1045, 2572, 8025, 1011, 3756, 2003, 1037, 2204, 2143, 2005, 3087, 5782, 2000, 2817, 1996, 6240, 1998, 14629, 1006, 2053, 26136, 3832, 1007, 1997, 4467, 5988, 1012, 2021, 2428, 1010, 2023, 2143, 2987, 1005, 1056, 2031, 2172, 1997, 1037, 5436, 1012, 102]\n",
            "Sample 1 - Tokens:  ['[CLS]', 'i', 'rented', 'i', 'am', 'curious', '-', 'yellow', 'from', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it', 'was', 'first', 'released', 'in', '1967', '.', 'i', 'also', 'heard', 'that', 'at', 'first', 'it', 'was', 'seized', 'by', 'u', '.', 's', '.', 'customs', 'if', 'it', 'ever', 'tried', 'to', 'enter', 'this', 'country', ',', 'therefore', 'being', 'a', 'fan', 'of', 'films', 'considered', '\"', 'controversial', '\"', 'i', 'really', 'had', 'to', 'see', 'this', 'for', 'myself', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'plot', 'is', 'centered', 'around', 'a', 'young', 'swedish', 'drama', 'student', 'named', 'lena', 'who', 'wants', 'to', 'learn', 'everything', 'she', 'can', 'about', 'life', '.', 'in', 'particular', 'she', 'wants', 'to', 'focus', 'her', 'attention', '##s', 'to', 'making', 'some', 'sort', 'of', 'documentary', 'on', 'what', 'the', 'average', 'sw', '##ede', 'thought', 'about', 'certain', 'political', 'issues', 'such', 'as', 'the', 'vietnam', 'war', 'and', 'race', 'issues', 'in', 'the', 'united', 'states', '.', 'in', 'between', 'asking', 'politicians', 'and', 'ordinary', 'den', '##ize', '##ns', 'of', 'stockholm', 'about', 'their', 'opinions', 'on', 'politics', ',', 'she', 'has', 'sex', 'with', 'her', 'drama', 'teacher', ',', 'classmates', ',', 'and', 'married', 'men', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'what', 'kills', 'me', 'about', 'i', 'am', 'curious', '-', 'yellow', 'is', 'that', '40', 'years', 'ago', ',', 'this', 'was', 'considered', 'pornographic', '.', 'really', ',', 'the', 'sex', 'and', 'nu', '##dity', 'scenes', 'are', 'few', 'and', 'far', 'between', ',', 'even', 'then', 'it', \"'\", 's', 'not', 'shot', 'like', 'some', 'cheap', '##ly', 'made', 'porn', '##o', '.', 'while', 'my', 'country', '##men', 'mind', 'find', 'it', 'shocking', ',', 'in', 'reality', 'sex', 'and', 'nu', '##dity', 'are', 'a', 'major', 'staple', 'in', 'swedish', 'cinema', '.', 'even', 'ing', '##mar', 'bergman', ',', 'arguably', 'their', 'answer', 'to', 'good', 'old', 'boy', 'john', 'ford', ',', 'had', 'sex', 'scenes', 'in', 'his', 'films', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'i', 'do', 'com', '##men', '##d', 'the', 'filmmakers', 'for', 'the', 'fact', 'that', 'any', 'sex', 'shown', 'in', 'the', 'film', 'is', 'shown', 'for', 'artistic', 'purposes', 'rather', 'than', 'just', 'to', 'shock', 'people', 'and', 'make', 'money', 'to', 'be', 'shown', 'in', 'pornographic', 'theaters', 'in', 'america', '.', 'i', 'am', 'curious', '-', 'yellow', 'is', 'a', 'good', 'film', 'for', 'anyone', 'wanting', 'to', 'study', 'the', 'meat', 'and', 'potatoes', '(', 'no', 'pun', 'intended', ')', 'of', 'swedish', 'cinema', '.', 'but', 'really', ',', 'this', 'film', 'doesn', \"'\", 't', 'have', 'much', 'of', 'a', 'plot', '.', '[SEP]']\n",
            "Vocabulary size:  30522\n"
          ]
        }
      ],
      "source": [
        "# Tokenized dataset has new data field \"input_ids\".\n",
        "# This field is a list of indices, each refers to one token in raw string.\n",
        "tokenized_train_set = tokenized_imdb[\"train\"]\n",
        "print(\"Sample 1 - Text: \", tokenized_train_set[0][\"text\"])\n",
        "print(\"Sample 1 - Token indices: \", tokenized_train_set[0][\"input_ids\"])\n",
        "\n",
        "# Getting vocabulary and inv vocabulary of BERT\n",
        "vocabulary = tokenizer.get_vocab()\n",
        "inv_vocab = {index: token for token, index in vocabulary.items()}\n",
        "\n",
        "# Mapping indices to tokens for sample 1\n",
        "tokens = [inv_vocab[index] for index in tokenized_train_set[0][\"input_ids\"]]\n",
        "print(\"Sample 1 - Tokens: \", tokens)\n",
        "\n",
        "# BERT - Vocabulary Size\n",
        "print(\"Vocabulary size: \", len(vocabulary))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCFiqds7-2dQ"
      },
      "source": [
        "### 3. Batching Tokens\n",
        "\n",
        "* In general, the sentences or paragraphs to be processed by the language model have different length; so after tokenization each sentence has different number of tokens. This is a problem, because batched inputs need to be fixed-size tensors, where padding enters the picture. It adds a special padding token to guarantee that all sequences have same length as the longest one or maximum length accepted by the model [\\[10\\]](https://huggingface.co/docs/transformers/en/pad_truncation#).\n",
        "\n",
        "* Our main purpose is to create a batch of padded samples. To achieve that, [`DataCollatorWithPadding`](https://huggingface.co/docs/transformers/v4.47.1/en/main_classes/data_collator#transformers.DataCollatorWithPadding) can be used. It dynamically pads the sequences to longest length in the batch during collation. As an alternative, all samples in the dataset can be also padded to maximum length, but we do not need this. What we need is that only the samples in the same batch should have same length. At this point, dynamic padding inside the batch becomes more efficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8Qt22j1aAeTu"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp-yarvriRdw"
      },
      "source": [
        "# Evaluate\n",
        "\n",
        "To be able to evaluate the performance of the model during training and validation steps, we need some metrics. The most used ones for classification is accuracy, precision and recall. We can use HF [evaluate](https://huggingface.co/docs/evaluate/en/index) library.\n",
        "\n",
        "We implement `compute_metrics()` function, which will be automatically invoked to calculate 3 evaluation metrics for validation set during training. When multiple metrics are calculated in this function, its return statement needs to be a dictionary [\\[11, ](https://huggingface.co/docs/transformers/en/main_classes/trainer)[12\\]](https://discuss.huggingface.co/t/combine-multiple-metrics-in-compute-metrics-for-validation/90088)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y_uBZ4m1fu77"
      },
      "outputs": [],
      "source": [
        "recall = evaluate.load(\"recall\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "\n",
        "def compute_metrics(preds_labels) -> dict:\n",
        "    preds, labels = preds_labels\n",
        "    preds = np.argmax(preds, axis=1)  # expected shape: (B, 2)\n",
        "\n",
        "    acc = accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
        "    rec = recall.compute(predictions=preds, references=labels)[\"recall\"]\n",
        "    pre = precision.compute(predictions=preds, references=labels)[\"precision\"]\n",
        "\n",
        "    return {\"accuracy\": acc, \"recall\": rec, \"precision\": pre}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ0PhDfrkMlA"
      },
      "source": [
        "# Training\n",
        "\n",
        "BERT classifier is extended version of BERT architecture [\\[13\\]](https://huggingface.co/docs/transformers/en/model_doc/bert); it has additional classification head at the top of pooled output. The embedding space is mapped into class space along with softmax activation.\n",
        "\n",
        "The parameters of each layer in BERT and BERT-classifier are stored in a dict, and how many parameter sets exist is counted. Then, they are simultaneously printed. We observe that the weights and biases of each layer are matched, but BERT classifier has additional weights and biases for classification head.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa5zJkp8kOIf",
        "outputId": "802a239a-60aa-4e51-82b7-0b89bd8642fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Number of param groups in BERT:  199\n",
            "Number of param groups in BERT Classifier:  201\n",
            "\n",
            "Layer Weights:\n",
            "--------------\n",
            "embeddings.word_embeddings.weight \t bert.embeddings.word_embeddings.weight\n",
            "embeddings.position_embeddings.weight \t bert.embeddings.position_embeddings.weight\n",
            "embeddings.token_type_embeddings.weight \t bert.embeddings.token_type_embeddings.weight\n",
            "embeddings.LayerNorm.weight \t bert.embeddings.LayerNorm.weight\n",
            "embeddings.LayerNorm.bias \t bert.embeddings.LayerNorm.bias\n",
            "encoder.layer.0.attention.self.query.weight \t bert.encoder.layer.0.attention.self.query.weight\n",
            "encoder.layer.0.attention.self.query.bias \t bert.encoder.layer.0.attention.self.query.bias\n",
            "encoder.layer.0.attention.self.key.weight \t bert.encoder.layer.0.attention.self.key.weight\n",
            "encoder.layer.0.attention.self.key.bias \t bert.encoder.layer.0.attention.self.key.bias\n",
            "encoder.layer.0.attention.self.value.weight \t bert.encoder.layer.0.attention.self.value.weight\n",
            "encoder.layer.0.attention.self.value.bias \t bert.encoder.layer.0.attention.self.value.bias\n",
            "encoder.layer.0.attention.output.dense.weight \t bert.encoder.layer.0.attention.output.dense.weight\n",
            "encoder.layer.0.attention.output.dense.bias \t bert.encoder.layer.0.attention.output.dense.bias\n",
            "encoder.layer.0.attention.output.LayerNorm.weight \t bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "encoder.layer.0.attention.output.LayerNorm.bias \t bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "encoder.layer.0.intermediate.dense.weight \t bert.encoder.layer.0.intermediate.dense.weight\n",
            "encoder.layer.0.intermediate.dense.bias \t bert.encoder.layer.0.intermediate.dense.bias\n",
            "encoder.layer.0.output.dense.weight \t bert.encoder.layer.0.output.dense.weight\n",
            "encoder.layer.0.output.dense.bias \t bert.encoder.layer.0.output.dense.bias\n",
            "encoder.layer.0.output.LayerNorm.weight \t bert.encoder.layer.0.output.LayerNorm.weight\n",
            "encoder.layer.0.output.LayerNorm.bias \t bert.encoder.layer.0.output.LayerNorm.bias\n",
            "encoder.layer.1.attention.self.query.weight \t bert.encoder.layer.1.attention.self.query.weight\n",
            "encoder.layer.1.attention.self.query.bias \t bert.encoder.layer.1.attention.self.query.bias\n",
            "encoder.layer.1.attention.self.key.weight \t bert.encoder.layer.1.attention.self.key.weight\n",
            "encoder.layer.1.attention.self.key.bias \t bert.encoder.layer.1.attention.self.key.bias\n",
            "encoder.layer.1.attention.self.value.weight \t bert.encoder.layer.1.attention.self.value.weight\n",
            "encoder.layer.1.attention.self.value.bias \t bert.encoder.layer.1.attention.self.value.bias\n",
            "encoder.layer.1.attention.output.dense.weight \t bert.encoder.layer.1.attention.output.dense.weight\n",
            "encoder.layer.1.attention.output.dense.bias \t bert.encoder.layer.1.attention.output.dense.bias\n",
            "encoder.layer.1.attention.output.LayerNorm.weight \t bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "encoder.layer.1.attention.output.LayerNorm.bias \t bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "encoder.layer.1.intermediate.dense.weight \t bert.encoder.layer.1.intermediate.dense.weight\n",
            "encoder.layer.1.intermediate.dense.bias \t bert.encoder.layer.1.intermediate.dense.bias\n",
            "encoder.layer.1.output.dense.weight \t bert.encoder.layer.1.output.dense.weight\n",
            "encoder.layer.1.output.dense.bias \t bert.encoder.layer.1.output.dense.bias\n",
            "encoder.layer.1.output.LayerNorm.weight \t bert.encoder.layer.1.output.LayerNorm.weight\n",
            "encoder.layer.1.output.LayerNorm.bias \t bert.encoder.layer.1.output.LayerNorm.bias\n",
            "encoder.layer.2.attention.self.query.weight \t bert.encoder.layer.2.attention.self.query.weight\n",
            "encoder.layer.2.attention.self.query.bias \t bert.encoder.layer.2.attention.self.query.bias\n",
            "encoder.layer.2.attention.self.key.weight \t bert.encoder.layer.2.attention.self.key.weight\n",
            "encoder.layer.2.attention.self.key.bias \t bert.encoder.layer.2.attention.self.key.bias\n",
            "encoder.layer.2.attention.self.value.weight \t bert.encoder.layer.2.attention.self.value.weight\n",
            "encoder.layer.2.attention.self.value.bias \t bert.encoder.layer.2.attention.self.value.bias\n",
            "encoder.layer.2.attention.output.dense.weight \t bert.encoder.layer.2.attention.output.dense.weight\n",
            "encoder.layer.2.attention.output.dense.bias \t bert.encoder.layer.2.attention.output.dense.bias\n",
            "encoder.layer.2.attention.output.LayerNorm.weight \t bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "encoder.layer.2.attention.output.LayerNorm.bias \t bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "encoder.layer.2.intermediate.dense.weight \t bert.encoder.layer.2.intermediate.dense.weight\n",
            "encoder.layer.2.intermediate.dense.bias \t bert.encoder.layer.2.intermediate.dense.bias\n",
            "encoder.layer.2.output.dense.weight \t bert.encoder.layer.2.output.dense.weight\n",
            "encoder.layer.2.output.dense.bias \t bert.encoder.layer.2.output.dense.bias\n",
            "encoder.layer.2.output.LayerNorm.weight \t bert.encoder.layer.2.output.LayerNorm.weight\n",
            "encoder.layer.2.output.LayerNorm.bias \t bert.encoder.layer.2.output.LayerNorm.bias\n",
            "encoder.layer.3.attention.self.query.weight \t bert.encoder.layer.3.attention.self.query.weight\n",
            "encoder.layer.3.attention.self.query.bias \t bert.encoder.layer.3.attention.self.query.bias\n",
            "encoder.layer.3.attention.self.key.weight \t bert.encoder.layer.3.attention.self.key.weight\n",
            "encoder.layer.3.attention.self.key.bias \t bert.encoder.layer.3.attention.self.key.bias\n",
            "encoder.layer.3.attention.self.value.weight \t bert.encoder.layer.3.attention.self.value.weight\n",
            "encoder.layer.3.attention.self.value.bias \t bert.encoder.layer.3.attention.self.value.bias\n",
            "encoder.layer.3.attention.output.dense.weight \t bert.encoder.layer.3.attention.output.dense.weight\n",
            "encoder.layer.3.attention.output.dense.bias \t bert.encoder.layer.3.attention.output.dense.bias\n",
            "encoder.layer.3.attention.output.LayerNorm.weight \t bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "encoder.layer.3.attention.output.LayerNorm.bias \t bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "encoder.layer.3.intermediate.dense.weight \t bert.encoder.layer.3.intermediate.dense.weight\n",
            "encoder.layer.3.intermediate.dense.bias \t bert.encoder.layer.3.intermediate.dense.bias\n",
            "encoder.layer.3.output.dense.weight \t bert.encoder.layer.3.output.dense.weight\n",
            "encoder.layer.3.output.dense.bias \t bert.encoder.layer.3.output.dense.bias\n",
            "encoder.layer.3.output.LayerNorm.weight \t bert.encoder.layer.3.output.LayerNorm.weight\n",
            "encoder.layer.3.output.LayerNorm.bias \t bert.encoder.layer.3.output.LayerNorm.bias\n",
            "encoder.layer.4.attention.self.query.weight \t bert.encoder.layer.4.attention.self.query.weight\n",
            "encoder.layer.4.attention.self.query.bias \t bert.encoder.layer.4.attention.self.query.bias\n",
            "encoder.layer.4.attention.self.key.weight \t bert.encoder.layer.4.attention.self.key.weight\n",
            "encoder.layer.4.attention.self.key.bias \t bert.encoder.layer.4.attention.self.key.bias\n",
            "encoder.layer.4.attention.self.value.weight \t bert.encoder.layer.4.attention.self.value.weight\n",
            "encoder.layer.4.attention.self.value.bias \t bert.encoder.layer.4.attention.self.value.bias\n",
            "encoder.layer.4.attention.output.dense.weight \t bert.encoder.layer.4.attention.output.dense.weight\n",
            "encoder.layer.4.attention.output.dense.bias \t bert.encoder.layer.4.attention.output.dense.bias\n",
            "encoder.layer.4.attention.output.LayerNorm.weight \t bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "encoder.layer.4.attention.output.LayerNorm.bias \t bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "encoder.layer.4.intermediate.dense.weight \t bert.encoder.layer.4.intermediate.dense.weight\n",
            "encoder.layer.4.intermediate.dense.bias \t bert.encoder.layer.4.intermediate.dense.bias\n",
            "encoder.layer.4.output.dense.weight \t bert.encoder.layer.4.output.dense.weight\n",
            "encoder.layer.4.output.dense.bias \t bert.encoder.layer.4.output.dense.bias\n",
            "encoder.layer.4.output.LayerNorm.weight \t bert.encoder.layer.4.output.LayerNorm.weight\n",
            "encoder.layer.4.output.LayerNorm.bias \t bert.encoder.layer.4.output.LayerNorm.bias\n",
            "encoder.layer.5.attention.self.query.weight \t bert.encoder.layer.5.attention.self.query.weight\n",
            "encoder.layer.5.attention.self.query.bias \t bert.encoder.layer.5.attention.self.query.bias\n",
            "encoder.layer.5.attention.self.key.weight \t bert.encoder.layer.5.attention.self.key.weight\n",
            "encoder.layer.5.attention.self.key.bias \t bert.encoder.layer.5.attention.self.key.bias\n",
            "encoder.layer.5.attention.self.value.weight \t bert.encoder.layer.5.attention.self.value.weight\n",
            "encoder.layer.5.attention.self.value.bias \t bert.encoder.layer.5.attention.self.value.bias\n",
            "encoder.layer.5.attention.output.dense.weight \t bert.encoder.layer.5.attention.output.dense.weight\n",
            "encoder.layer.5.attention.output.dense.bias \t bert.encoder.layer.5.attention.output.dense.bias\n",
            "encoder.layer.5.attention.output.LayerNorm.weight \t bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "encoder.layer.5.attention.output.LayerNorm.bias \t bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "encoder.layer.5.intermediate.dense.weight \t bert.encoder.layer.5.intermediate.dense.weight\n",
            "encoder.layer.5.intermediate.dense.bias \t bert.encoder.layer.5.intermediate.dense.bias\n",
            "encoder.layer.5.output.dense.weight \t bert.encoder.layer.5.output.dense.weight\n",
            "encoder.layer.5.output.dense.bias \t bert.encoder.layer.5.output.dense.bias\n",
            "encoder.layer.5.output.LayerNorm.weight \t bert.encoder.layer.5.output.LayerNorm.weight\n",
            "encoder.layer.5.output.LayerNorm.bias \t bert.encoder.layer.5.output.LayerNorm.bias\n",
            "encoder.layer.6.attention.self.query.weight \t bert.encoder.layer.6.attention.self.query.weight\n",
            "encoder.layer.6.attention.self.query.bias \t bert.encoder.layer.6.attention.self.query.bias\n",
            "encoder.layer.6.attention.self.key.weight \t bert.encoder.layer.6.attention.self.key.weight\n",
            "encoder.layer.6.attention.self.key.bias \t bert.encoder.layer.6.attention.self.key.bias\n",
            "encoder.layer.6.attention.self.value.weight \t bert.encoder.layer.6.attention.self.value.weight\n",
            "encoder.layer.6.attention.self.value.bias \t bert.encoder.layer.6.attention.self.value.bias\n",
            "encoder.layer.6.attention.output.dense.weight \t bert.encoder.layer.6.attention.output.dense.weight\n",
            "encoder.layer.6.attention.output.dense.bias \t bert.encoder.layer.6.attention.output.dense.bias\n",
            "encoder.layer.6.attention.output.LayerNorm.weight \t bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "encoder.layer.6.attention.output.LayerNorm.bias \t bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "encoder.layer.6.intermediate.dense.weight \t bert.encoder.layer.6.intermediate.dense.weight\n",
            "encoder.layer.6.intermediate.dense.bias \t bert.encoder.layer.6.intermediate.dense.bias\n",
            "encoder.layer.6.output.dense.weight \t bert.encoder.layer.6.output.dense.weight\n",
            "encoder.layer.6.output.dense.bias \t bert.encoder.layer.6.output.dense.bias\n",
            "encoder.layer.6.output.LayerNorm.weight \t bert.encoder.layer.6.output.LayerNorm.weight\n",
            "encoder.layer.6.output.LayerNorm.bias \t bert.encoder.layer.6.output.LayerNorm.bias\n",
            "encoder.layer.7.attention.self.query.weight \t bert.encoder.layer.7.attention.self.query.weight\n",
            "encoder.layer.7.attention.self.query.bias \t bert.encoder.layer.7.attention.self.query.bias\n",
            "encoder.layer.7.attention.self.key.weight \t bert.encoder.layer.7.attention.self.key.weight\n",
            "encoder.layer.7.attention.self.key.bias \t bert.encoder.layer.7.attention.self.key.bias\n",
            "encoder.layer.7.attention.self.value.weight \t bert.encoder.layer.7.attention.self.value.weight\n",
            "encoder.layer.7.attention.self.value.bias \t bert.encoder.layer.7.attention.self.value.bias\n",
            "encoder.layer.7.attention.output.dense.weight \t bert.encoder.layer.7.attention.output.dense.weight\n",
            "encoder.layer.7.attention.output.dense.bias \t bert.encoder.layer.7.attention.output.dense.bias\n",
            "encoder.layer.7.attention.output.LayerNorm.weight \t bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "encoder.layer.7.attention.output.LayerNorm.bias \t bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "encoder.layer.7.intermediate.dense.weight \t bert.encoder.layer.7.intermediate.dense.weight\n",
            "encoder.layer.7.intermediate.dense.bias \t bert.encoder.layer.7.intermediate.dense.bias\n",
            "encoder.layer.7.output.dense.weight \t bert.encoder.layer.7.output.dense.weight\n",
            "encoder.layer.7.output.dense.bias \t bert.encoder.layer.7.output.dense.bias\n",
            "encoder.layer.7.output.LayerNorm.weight \t bert.encoder.layer.7.output.LayerNorm.weight\n",
            "encoder.layer.7.output.LayerNorm.bias \t bert.encoder.layer.7.output.LayerNorm.bias\n",
            "encoder.layer.8.attention.self.query.weight \t bert.encoder.layer.8.attention.self.query.weight\n",
            "encoder.layer.8.attention.self.query.bias \t bert.encoder.layer.8.attention.self.query.bias\n",
            "encoder.layer.8.attention.self.key.weight \t bert.encoder.layer.8.attention.self.key.weight\n",
            "encoder.layer.8.attention.self.key.bias \t bert.encoder.layer.8.attention.self.key.bias\n",
            "encoder.layer.8.attention.self.value.weight \t bert.encoder.layer.8.attention.self.value.weight\n",
            "encoder.layer.8.attention.self.value.bias \t bert.encoder.layer.8.attention.self.value.bias\n",
            "encoder.layer.8.attention.output.dense.weight \t bert.encoder.layer.8.attention.output.dense.weight\n",
            "encoder.layer.8.attention.output.dense.bias \t bert.encoder.layer.8.attention.output.dense.bias\n",
            "encoder.layer.8.attention.output.LayerNorm.weight \t bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "encoder.layer.8.attention.output.LayerNorm.bias \t bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "encoder.layer.8.intermediate.dense.weight \t bert.encoder.layer.8.intermediate.dense.weight\n",
            "encoder.layer.8.intermediate.dense.bias \t bert.encoder.layer.8.intermediate.dense.bias\n",
            "encoder.layer.8.output.dense.weight \t bert.encoder.layer.8.output.dense.weight\n",
            "encoder.layer.8.output.dense.bias \t bert.encoder.layer.8.output.dense.bias\n",
            "encoder.layer.8.output.LayerNorm.weight \t bert.encoder.layer.8.output.LayerNorm.weight\n",
            "encoder.layer.8.output.LayerNorm.bias \t bert.encoder.layer.8.output.LayerNorm.bias\n",
            "encoder.layer.9.attention.self.query.weight \t bert.encoder.layer.9.attention.self.query.weight\n",
            "encoder.layer.9.attention.self.query.bias \t bert.encoder.layer.9.attention.self.query.bias\n",
            "encoder.layer.9.attention.self.key.weight \t bert.encoder.layer.9.attention.self.key.weight\n",
            "encoder.layer.9.attention.self.key.bias \t bert.encoder.layer.9.attention.self.key.bias\n",
            "encoder.layer.9.attention.self.value.weight \t bert.encoder.layer.9.attention.self.value.weight\n",
            "encoder.layer.9.attention.self.value.bias \t bert.encoder.layer.9.attention.self.value.bias\n",
            "encoder.layer.9.attention.output.dense.weight \t bert.encoder.layer.9.attention.output.dense.weight\n",
            "encoder.layer.9.attention.output.dense.bias \t bert.encoder.layer.9.attention.output.dense.bias\n",
            "encoder.layer.9.attention.output.LayerNorm.weight \t bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "encoder.layer.9.attention.output.LayerNorm.bias \t bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "encoder.layer.9.intermediate.dense.weight \t bert.encoder.layer.9.intermediate.dense.weight\n",
            "encoder.layer.9.intermediate.dense.bias \t bert.encoder.layer.9.intermediate.dense.bias\n",
            "encoder.layer.9.output.dense.weight \t bert.encoder.layer.9.output.dense.weight\n",
            "encoder.layer.9.output.dense.bias \t bert.encoder.layer.9.output.dense.bias\n",
            "encoder.layer.9.output.LayerNorm.weight \t bert.encoder.layer.9.output.LayerNorm.weight\n",
            "encoder.layer.9.output.LayerNorm.bias \t bert.encoder.layer.9.output.LayerNorm.bias\n",
            "encoder.layer.10.attention.self.query.weight \t bert.encoder.layer.10.attention.self.query.weight\n",
            "encoder.layer.10.attention.self.query.bias \t bert.encoder.layer.10.attention.self.query.bias\n",
            "encoder.layer.10.attention.self.key.weight \t bert.encoder.layer.10.attention.self.key.weight\n",
            "encoder.layer.10.attention.self.key.bias \t bert.encoder.layer.10.attention.self.key.bias\n",
            "encoder.layer.10.attention.self.value.weight \t bert.encoder.layer.10.attention.self.value.weight\n",
            "encoder.layer.10.attention.self.value.bias \t bert.encoder.layer.10.attention.self.value.bias\n",
            "encoder.layer.10.attention.output.dense.weight \t bert.encoder.layer.10.attention.output.dense.weight\n",
            "encoder.layer.10.attention.output.dense.bias \t bert.encoder.layer.10.attention.output.dense.bias\n",
            "encoder.layer.10.attention.output.LayerNorm.weight \t bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "encoder.layer.10.attention.output.LayerNorm.bias \t bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "encoder.layer.10.intermediate.dense.weight \t bert.encoder.layer.10.intermediate.dense.weight\n",
            "encoder.layer.10.intermediate.dense.bias \t bert.encoder.layer.10.intermediate.dense.bias\n",
            "encoder.layer.10.output.dense.weight \t bert.encoder.layer.10.output.dense.weight\n",
            "encoder.layer.10.output.dense.bias \t bert.encoder.layer.10.output.dense.bias\n",
            "encoder.layer.10.output.LayerNorm.weight \t bert.encoder.layer.10.output.LayerNorm.weight\n",
            "encoder.layer.10.output.LayerNorm.bias \t bert.encoder.layer.10.output.LayerNorm.bias\n",
            "encoder.layer.11.attention.self.query.weight \t bert.encoder.layer.11.attention.self.query.weight\n",
            "encoder.layer.11.attention.self.query.bias \t bert.encoder.layer.11.attention.self.query.bias\n",
            "encoder.layer.11.attention.self.key.weight \t bert.encoder.layer.11.attention.self.key.weight\n",
            "encoder.layer.11.attention.self.key.bias \t bert.encoder.layer.11.attention.self.key.bias\n",
            "encoder.layer.11.attention.self.value.weight \t bert.encoder.layer.11.attention.self.value.weight\n",
            "encoder.layer.11.attention.self.value.bias \t bert.encoder.layer.11.attention.self.value.bias\n",
            "encoder.layer.11.attention.output.dense.weight \t bert.encoder.layer.11.attention.output.dense.weight\n",
            "encoder.layer.11.attention.output.dense.bias \t bert.encoder.layer.11.attention.output.dense.bias\n",
            "encoder.layer.11.attention.output.LayerNorm.weight \t bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "encoder.layer.11.attention.output.LayerNorm.bias \t bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "encoder.layer.11.intermediate.dense.weight \t bert.encoder.layer.11.intermediate.dense.weight\n",
            "encoder.layer.11.intermediate.dense.bias \t bert.encoder.layer.11.intermediate.dense.bias\n",
            "encoder.layer.11.output.dense.weight \t bert.encoder.layer.11.output.dense.weight\n",
            "encoder.layer.11.output.dense.bias \t bert.encoder.layer.11.output.dense.bias\n",
            "encoder.layer.11.output.LayerNorm.weight \t bert.encoder.layer.11.output.LayerNorm.weight\n",
            "encoder.layer.11.output.LayerNorm.bias \t bert.encoder.layer.11.output.LayerNorm.bias\n",
            "pooler.dense.weight \t bert.pooler.dense.weight\n",
            "pooler.dense.bias \t bert.pooler.dense.bias\n",
            " \t classifier.weight\n",
            " \t classifier.bias\n",
            "torch.Size([2, 768])\n"
          ]
        }
      ],
      "source": [
        "# Dictionaries to map from class ids to corresponding labels or vice versa.\n",
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
        "\n",
        "# instantiating bert model and its text classifier version\n",
        "bert = AutoModel.from_pretrained(\"google-bert/bert-base-uncased\")\n",
        "bert_classifier = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"google-bert/bert-base-uncased\",\n",
        "    num_labels=2,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")\n",
        "\n",
        "# going through BERT\n",
        "num_layers, bert_dict = 0, {}\n",
        "for name, module in bert.named_parameters():\n",
        "    bert_dict[name] = module\n",
        "    num_layers += 1\n",
        "print(\"\\nNumber of param groups in BERT: \", num_layers)\n",
        "\n",
        "# going through BERT classifier\n",
        "num_layers, bert_classifier_dict = 0, {}\n",
        "for name, module in bert_classifier.named_parameters():\n",
        "    bert_classifier_dict[name] = module\n",
        "    num_layers += 1\n",
        "print(\"Number of param groups in BERT Classifier: \", num_layers)\n",
        "\n",
        "# Comparison between their layers\n",
        "layer_names1 = list(bert_dict.keys()) + [\"\", \"\"]\n",
        "layer_names2 = list(bert_classifier_dict.keys())\n",
        "\n",
        "print(\"\\nLayer Weights:\")\n",
        "print(\"--------------\")\n",
        "for name1, name2 in zip(layer_names1, layer_names2):\n",
        "    print(name1, \"\\t\", name2)\n",
        "\n",
        "print(bert_classifier_dict[\"classifier.weight\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOrtd7KnyJAC"
      },
      "source": [
        "## Training Arguments and Trainer\n",
        "\n",
        "To train the model, we need to determine hyperparameters, which is handled by `TrainingArguments` [\\[11\\]](https://huggingface.co/docs/transformers/en/main_classes/trainer).\n",
        "\n",
        "- ***output_dir:*** The directory where model predictions and checkpoints will be saved.\n",
        "\n",
        "- ***per_device_train_batch_size:*** When you train your model with multiple GPUs or TPUs, it controls the batch size for each GPU/TPU.\n",
        "\n",
        "- ***per_device_eval_batch_size:*** When you evaluate your model with multiple GPUs or TPUs, it controls the batch size for each GPU/TPU.\n",
        "\n",
        "- ***num_train_epochs:*** How many number of epochs the model will be trained.\n",
        "\n",
        "- ***eval_strategy:*** It can be \"no\", \"steps\", or \"epoch\".\n",
        "    - no: No evaluation is done during training\n",
        "    - steps: Evaluation is done and logged every *\\\"eval_steps\\\"*\n",
        "    - epoch: Evaluation is done at the end of each epoch.\n",
        "\n",
        "\n",
        "- ***save_strategy:*** It can be \"no\", \"steps\", \"epoch\", \"best\".\n",
        "    - no: No ckpt save is done during training\n",
        "    - steps: Ckpt save is done every *\\\"eval_steps\\\"*\n",
        "    - epoch: Ckpt save is done at the end of each epoch.\n",
        "    - best: Ckpt save is done when a new *\\\"best_metric\\\"* achieved.\n",
        "\n",
        "- ***load_best_model_at_end:*** It is a boolean value to make sure whether the best model according to `metric_for_best_model` will be saved or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "rppmG_G_lj0q",
        "outputId": "4321d1ee-d3ce-46fc-a1c3-7c37687d35c9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6252' max='6252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6252/6252 43:58, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.209900</td>\n",
              "      <td>0.245650</td>\n",
              "      <td>0.910160</td>\n",
              "      <td>0.848080</td>\n",
              "      <td>0.968305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.137900</td>\n",
              "      <td>0.244284</td>\n",
              "      <td>0.927400</td>\n",
              "      <td>0.891120</td>\n",
              "      <td>0.960838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.075200</td>\n",
              "      <td>0.284517</td>\n",
              "      <td>0.939080</td>\n",
              "      <td>0.950880</td>\n",
              "      <td>0.928957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.035200</td>\n",
              "      <td>0.311895</td>\n",
              "      <td>0.940280</td>\n",
              "      <td>0.942960</td>\n",
              "      <td>0.937933</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6252, training_loss=0.12284956799053795, metrics={'train_runtime': 2639.6527, 'train_samples_per_second': 37.884, 'train_steps_per_second': 2.368, 'total_flos': 2.603344526150064e+16, 'train_loss': 0.12284956799053795, 'epoch': 4.0})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"bert_imdb\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=bert_classifier,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb[\"train\"],\n",
        "    eval_dataset=tokenized_imdb[\"test\"],\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "qsoujn7f5de0",
        "outputId": "34c75db8-61d7-4e10-cb07-10f68b9fa757"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/goktug14/bert_imdb/commit/7e21762b691fd87d11d9fbccd299d5b21ba9bf4c', commit_message='End of training', commit_description='', oid='7e21762b691fd87d11d9fbccd299d5b21ba9bf4c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/goktug14/bert_imdb', endpoint='https://huggingface.co', repo_type='model', repo_id='goktug14/bert_imdb'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFk4bcV87Phf"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCiGcfNL7RMH",
        "outputId": "c8315a4b-0b3c-4563-998d-0c988358f522"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9953957200050354}]\n",
            "[{'label': 'NEGATIVE', 'score': 0.995867133140564}]\n"
          ]
        }
      ],
      "source": [
        "# 9/10 - substance - 2024\n",
        "text1 = \"\"\"This is one of those movies that would not do justice seeing at home.\n",
        "          You need to be in a packed theater, feel the waves and rushes of energy\n",
        "          from the crowd. It is an experience to say the least. You will laugh,\n",
        "          you will look away, your jaw will drop, you will feel uncomfortable.\n",
        "          But it is all worth it. It is incredible filmmaking, award winning acting\n",
        "          and a smashing soundtrack all in one. Huge applause to Demi for taking\n",
        "          on such a vulnerable role covering a subject that is rarely discussed.\n",
        "          Looking forward to see what comes of this, hopefully more open conversation\n",
        "          within the industry and more doors opened than closed.\"\"\"\n",
        "\n",
        "# 4/10 - smile 2 - 2024\n",
        "text2 = \"\"\"Smile 2 boasted impressive cinematography and strong performances, yet\n",
        "         ultimately stumbled due to a shallow plot and a poorly developed core\n",
        "         concept. The film revolves around a core demon spirit, a chiling premise\n",
        "          that unfortunately remained largely unexplored.\"\"\"\n",
        "\n",
        "model = pipeline(\"sentiment-analysis\", model=\"goktug14/bert_imdb\")\n",
        "\n",
        "out1 = model(text1)\n",
        "out2 = model(text2)\n",
        "\n",
        "print(out1)\n",
        "print(out2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJrg30d_5xcY"
      },
      "source": [
        "<a name=\"ref\"></a>\n",
        "\n",
        "# References\n",
        "\n",
        "1. [HF Tutorial](https://huggingface.co/docs/transformers/en/tasks/sequence_classification#inference)\n",
        "\n",
        "2. [Imdb Dataset](https://huggingface.co/datasets/stanfordnlp/imdb)\n",
        "\n",
        "3. [Tokenizer Documentation](https://huggingface.co/docs/transformers/main_classes/tokenizer)\n",
        "\n",
        "4. [Standard/Fast Tokenizer Discussion](https://discuss.huggingface.co/t/difference-betweeen-distilberttokenizerfast-and-distilberttokenizer/5961/2)\n",
        "\n",
        "5. [Uncased BERT Models](https://huggingface.co/google-bert/bert-base-uncased)\n",
        "\n",
        "6. [Batch Mapping in Datasets](https://huggingface.co/docs/datasets/en/about_map_batch)\n",
        "\n",
        "7. [PreTrainedTokenizerBase Class](https://huggingface.co/docs/transformers/internal/tokenization_utils)\n",
        "\n",
        "8. [Sub-Word Tokenization](https://www.youtube.com/watch?v=zHvTiHr506c)\n",
        "\n",
        "9. [Summary of Tokenizers](https://huggingface.co/docs/transformers/en/tokenizer_summary)\n",
        "\n",
        "10. [Padding and Truncation](https://huggingface.co/docs/transformers/en/pad_truncation#)\n",
        "\n",
        "11. [Compute Metrics and Trainer](https://huggingface.co/docs/transformers/en/main_classes/trainer)\n",
        "\n",
        "12. [Computation of Multiple Metrics Discussion](https://discuss.huggingface.co/t/combine-multiple-metrics-in-compute-metrics-for-validation/90088)\n",
        "\n",
        "13. [BERT Architecture](https://huggingface.co/docs/transformers/en/model_doc/bert)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09c0b13193bf41499dbea7c1f70c1ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8819eaa0882a429ca6e3c1c56997be82",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f7ac23eb3404a7fbd96a57252df8821",
            "value": 50000
          }
        },
        "13d535dfad0d40f9b06fbab79d0e4dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a5d61380ab744e591affa76f4847473",
              "IPY_MODEL_09c0b13193bf41499dbea7c1f70c1ad9",
              "IPY_MODEL_3786b632bca74e3d9a3b9a38a980719b"
            ],
            "layout": "IPY_MODEL_2ee2e2b7a7724c9cb7d2da514f683777"
          }
        },
        "2a5d61380ab744e591affa76f4847473": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_693c3b0c2ee242f8a7aa40302fc25124",
            "placeholder": "​",
            "style": "IPY_MODEL_a49e851e0dc34877b59a7fc536c54b9c",
            "value": "Map: 100%"
          }
        },
        "2ee2e2b7a7724c9cb7d2da514f683777": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f5d190020314cb2992230a56054f056": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3786b632bca74e3d9a3b9a38a980719b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91851d9d18514c17acc38ccee0189626",
            "placeholder": "​",
            "style": "IPY_MODEL_ee434fe3283946329078c09d61bf3eaf",
            "value": " 50000/50000 [00:14&lt;00:00, 3313.38 examples/s]"
          }
        },
        "447a72e2a7cc4f0e8c7149faf1599671": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_7a7c5d7b811b4a6bb8d2ed03d7e06180",
            "style": "IPY_MODEL_c5996703100c4e97ab2fd28d5963b73d",
            "value": false
          }
        },
        "4f7ac23eb3404a7fbd96a57252df8821": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5241f8a6069f4c728f7dcf2ff920f297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5a9c9937048d4813b8ba80427ac499b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_700f55d9671d4d7a971886881e1b452c",
            "placeholder": "​",
            "style": "IPY_MODEL_2f5d190020314cb2992230a56054f056",
            "value": ""
          }
        },
        "63c519f3c11b4810952d071c840c9550": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e7ea7d05c9c44909cd3c56de00d1992",
            "placeholder": "​",
            "style": "IPY_MODEL_b8a64962cdeb4eae98a4b7389db1adc9",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "680770bcd6ac404f8fe6c16026ed894a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "693c3b0c2ee242f8a7aa40302fc25124": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "700f55d9671d4d7a971886881e1b452c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a7c5d7b811b4a6bb8d2ed03d7e06180": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e7ea7d05c9c44909cd3c56de00d1992": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8819eaa0882a429ca6e3c1c56997be82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e83297ee54145048cb2dee5ec7c252e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d964f25e76be4ecc8e24a075b8d50282",
            "placeholder": "​",
            "style": "IPY_MODEL_a265fa8289cd40609cd545ab1b6a37e7",
            "value": "Connecting..."
          }
        },
        "91851d9d18514c17acc38ccee0189626": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "940a3e171ca04d80bd7439f87eb65da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9ca49c2047c46b789ff200a4363361a",
            "placeholder": "​",
            "style": "IPY_MODEL_680770bcd6ac404f8fe6c16026ed894a",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "994cd258b30a4876b2c09bb94e38fec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a5c858de69d34da396e21d69dda47175",
            "style": "IPY_MODEL_5241f8a6069f4c728f7dcf2ff920f297",
            "tooltip": ""
          }
        },
        "a265fa8289cd40609cd545ab1b6a37e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a49e851e0dc34877b59a7fc536c54b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5c858de69d34da396e21d69dda47175": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a64962cdeb4eae98a4b7389db1adc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbd9cffffed443f9a761ed4a6f171791": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "c5996703100c4e97ab2fd28d5963b73d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d964f25e76be4ecc8e24a075b8d50282": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee434fe3283946329078c09d61bf3eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9ca49c2047c46b789ff200a4363361a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb1b40087064990a056c77a034aab4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_bbd9cffffed443f9a761ed4a6f171791"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
